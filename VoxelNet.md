# VoxelNet

## 题目：VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection

### 摘要

在 3D 点云中准确检测对象是许多应用中的核心问题，例如自主导航、家政机器人和增强/虚拟现实。为了将高度稀疏的 LiDAR 点云与区域提议网络 (RPN) 连接起来，现有的大多数工作都集中在手工制作的特征表示上，例如，鸟瞰图投影。在这项工作中，我们消除了对 3D 点云进行手动特征工程的需要，并提出了 VoxelNet，这是一种通用的 3D 检测网络，将特征提取和边界框预测统一到一个阶段，端到端可训练的深度网络中。具体来说，VoxelNet 将点云划分为等距的 3D 体素，并通过新引入的体素特征编码 (VFE) 层将每个体素内的一组点转换为统一的特征表示。通过这种方式，点云被编码为描述性的体积表示，然后连接到 RPN 以生成检测。在 KITTI 汽车检测基准上的实验表明，VoxelNet 在很大程度上优于最先进的基于 LiDAR 的 3D 检测方法。

此外，我们的网络学习了具有各种几何形状的物体的有效判别表示，从而在仅基于 LiDAR 的行人和骑自行车者的 3D 检测中取得了令人鼓舞的结果。然后将其连接到 RPN 以生成检测。在 KITTI 汽车检测基准上的实验表明，VoxelNet 在很大程度上优于最先进的基于 LiDAR 的 3D 检测方法。此外，我们的网络学习了具有各种几何形状的物体的有效判别表示，从而在仅基于 LiDAR 的行人和骑自行车者的 3D 检测中取得了令人鼓舞的结果。然后将其连接到 RPN 以生成检测。在 KITTI 汽车检测基准上的实验表明，VoxelNet 在很大程度上优于最先进的基于 LiDAR 的 3D 检测方法。此外，我们的网络学习了具有各种几何形状的物体的有效判别表示，从而在仅基于 LiDAR 的行人和骑自行车者的 3D 检测中取得了令人鼓舞的结果。

### 引言

基于点云的 3D 对象检测是各种实际应用的重要组成部分，例如自主导航[11]、[14]、家政机器人[28]和增强/虚拟现实[29]。与基于图像的检测相比，LiDAR 提供可靠的深度信息，可用于准确定位对象并表征其形状[21]、[5]. 然而，与图像不同的是，由于 3D 空间的非均匀采样、传感器的有效范围、遮挡和相对姿态等因素，LiDAR 点云是稀疏的并且具有高度可变的点密度。为了应对这些挑战，许多方法为点云手动制作了特征表示，这些特征表示针对 3D 对象检测进行了调整。几种方法将点云投影到透视图中并应用基于图像的特征提取技术[30]、[15]、[22]。其他方法将点云栅格化为 3D 体素网格，并使用手工制作的特征对每个体素进行编码[43]、[9]、[39]、[40]、[21]、[5]。然而，这些手动设计选择引入了信息瓶颈，阻止这些方法有效利用 3D 形状信息和检测任务所需的不变性。图像识别[20]和检测[13]任务的重大突破是由于从手工制作的特征转向机器学习的特征。

最近，齐*等人。* [31]提出了 PointNet，这是一种端到端的深度神经网络，可以直接从点云中学习逐点特征。这种方法在 3D 对象识别、3D 对象部分分割和逐点语义分割任务上取得了令人印象深刻的结果。在[32] 中，引入了 PointNet 的改进版本，使网络能够学习不同尺度的局部结构。为了获得令人满意的结果，这两种方法在所有输入点（~1k 点）上训练了特征转换器网络。由于使用 LiDAR 获得的典型点云包含*约 10 万*个点，因此按照[31]、[32] 中的方法训练架构导致高计算和内存要求。将 3D 特征学习网络扩展到更多数量级的点和 3D 检测任务是我们在本文中解决的主要挑战。

区域提议网络 (RPN) [34]是一种高度优化的算法，用于高效的目标检测[17]、[5]、[33]、[24]。然而，这种方法需要密集的数据并以张量结构（例如图像、视频）进行组织，这对于典型的 LiDAR 点云而言并非如此。在本文中，我们缩小了用于 3D 检测任务的点集特征学习和 RPN 之间的差距。

我们提出了 VoxelNet，这是一种通用的 3D 检测框架，它同时以端到端的方式从点云中学习判别特征表示并预测准确的 3D 边界框，如图 2所示。我们设计了一种新颖的体素特征编码 (VFE) 层，通过将逐点特征与局部聚合特征相结合，可以实现体素内的点间交互。

堆叠多个 VFE 层允许学习用于表征局部 3D 形状信息的复杂特征。具体来说，VoxelNet 将点云划分为等距的 3D 体素，通过堆叠的 VFE 层对每个体素进行编码，然后 3D 卷积进一步聚合局部体素特征，将点云转换为高维体积表示。最后，RPN 使用体积表示并产生检测结果。这种高效的算法受益于稀疏点结构和体素网格上的高效并行处理。

我们在 KITTI 基准[11]提供的鸟瞰检测和全 3D 检测任务上评估 VoxelNet 。实验结果表明，VoxelNet 在很大程度上优于最先进的基于 LiDAR 的 3D 检测方法。我们还证明了 Voxel-Net 在从 LiDAR 点云检测行人和骑自行车的人方面取得了非常令人鼓舞的结果。

### 相关工作

3D 传感器技术的快速发展促使研究人员开发有效的表示方法来检测和定位点云中的对象。一些早期的特征表示方法是[41]、[8]、[7]、[19]、[42]、[35]、[6]、[27]、[1]、[36]、[ 2]、[25]、[26]. 当丰富详细的 3D 形状信息可用时，这些手工制作的特征会产生令人满意的结果。然而，它们无法适应更复杂的形状和场景，也无法从数据中学习所需的不变性，这导致在自主导航等不受控制的场景中取得有限的成功。

鉴于图像提供了详细的纹理信息，许多算法从 2D 图像[4]、[3]、[44]、[45]、[46]、[38]推断出 3D 边界框。然而，基于图像的 3D 检测方法的准确性受深度估计的准确性限制。

几种基于 LIDAR 的 3D 对象检测技术利用体素网格表示。[43] , [9]用 6 个统计量对每个非空体素进行编码，这些统计量来自体素中包含的所有点。[39]融合了多个局部统计数据来表示每个体素。[40]计算体素网格上的截断符号距离。[21]对 3D 体素网格使用二进制编码。[5]通过计算鸟瞰图中的多通道特征图和正面视图中的圆柱坐标，引入了 LiDAR 点云的多视图表示。其他几项研究将点云投影到透视图上，然后使用基于图像的特征编码方案[30]、[15]、[22]。

还有几种多模态融合方法将图像和激光雷达相结合，以提高检测精度[10]、[16]、[5]。与仅使用 LiDAR 的 3D 检测相比，这些方法提供了改进的性能，特别是对于小物体（行人、骑自行车者）或物体距离较远时，因为相机提供的测量值比 LiDAR 高一个数量级。然而，需要与 LiDAR 时间同步和校准的额外相机限制了它们的使用，并使解决方案对传感器故障模式更加敏感。在这项工作中，我们专注于仅 LiDAR 检测。

### 贡献

- 我们提出了一种新颖的端到端可训练深度架构，用于基于点云的 3D 检测 VoxelNet，它直接对稀疏 3D 点进行操作，避免了手动特征工程引入的信息瓶颈。

- 我们提出了一种实现 VoxelNet 的有效方法，该方法受益于稀疏点结构和体素网格上的高效并行处理。

- 我们在**KITTI**基准测试中进行了实验，并表明 VoxelNet 在基于 LiDAR 的汽车、行人和骑自行车者检测基准中产生了最先进的结果。

  ### 体素网架构

提议的 VoxelNet 由三个功能块组成：[（1）](https://ieeexplore.ieee.org/document/#deqn1)特征学习网络，[（2）](https://ieeexplore.ieee.org/document/#deqn2)卷积中间层，以及（3）区域提议网络[34]，如图 2 所示。我们将在以下部分详细介绍 VoxelNet。

#### 特征学习网络

体素分区：给定一个点云，我们将 3D 空间细分为等距的体素，如图 2所示。假设点云包含具有范围的 3D 空间d ^ h, W分别沿 Z、Y、X 轴。我们定义每个体素的大小vD,vH， 和 v宽因此。生成的 3D 体素网格的大小D′= D /vn.H′= H/ vH.宽′= W/v宽. 在这里，为了简单起见，我们假设d ，^ h, W 是多个 vD,vH,v宽

分组：我们根据它们所在的体素对这些点进行分组。由于距离、遮挡、物体的相对姿态和非均匀采样等因素，LiDAR 点云是稀疏的，并且在整个空间中具有高度可变的点密度。因此，在分组之后，体素将包含可变数量的点。如图 2所示，其中 Voxel-1 的点明显多于 Voxel-2 和 Voxel-4，而 Voxel-3 不包含任何点。

随机抽样：通常，高清 LiDAR 点云由*约 10 万*个点组成。直接处理所有点不仅会增加计算平台的内存/效率负担，而且整个空间中高度可变的点密度可能会使检测产生偏差。为此，我们随机抽样一个固定数量，吨 来自那些体素包含超过 吨点。这种采样策略有两个目的，[（1）](https://ieeexplore.ieee.org/document/#deqn1)计算节省（详见2.3 节）；和[（2）](https://ieeexplore.ieee.org/document/#deqn2)减小的点从而降低了采样偏压的体素之间的不平衡，并且增加了更多的变化来训练。

#### 堆叠体素特征编码

关键创新是 VFE 层链。为简单起见，图 2说明了一个体素的分层特征编码过程。不失一般性，我们在下一段中使用 VFE 第 1 层来描述细节。图 3显示了 VFE 第 1 层的架构。

表示 V = {磷一世= ⌈X一种.v0.z0.r01吨∈电阻4}我= 1 作为一个非空体素包含 吨≤ Ť LiDAR 点，其中 P 一世 包含 XYZ 坐标 i - th 点和 r一世是接收到的反射率。我们首先计算局部均值作为 V 中所有点的质心，表示为(vX, vμ, vz)

然后我们用质心的相对偏移量增加每个点 Pi 并获得输入特征集 Yin = {磷^一世= ⌈X一世,是一世,z一世,r一世,X一世-vX, ′是一世-vv,z一世-vz⌉1∈电阻7}我= 1 … t 接下来，每个 Pi 通过全连接网络 (FCN) 转换为特征空间，我们可以在其中聚合来自点特征的信息 F一世∈电阻米对包含在体素中的表面形状进行编码。FCN 由线性层、批归一化 (BN) 层和整流线性单元 (ReLU) 层组成。在获得逐点特征表示后，我们对与**V**关联的所有*f i*使用逐元素 MaxPooling来获得局部聚合特征F~∈电阻米对于 V。最后，我们用 f增加每个*f i*以形成逐点连接特征为FØ ü Ť一世= [F吨一世,F~吨]吨∈电阻2米 这样我们就得到了输出特征集 伏出去= {FØ ü Ť一世}我，Ť 所有非空体素都以相同的方式编码，并且它们在 FCN 中共享相同的参数集。

我们使用 VFE-i( *C in , C out* ) 来表示第 i 个 VFE 层，该层将维度*Cin 的*输入特征转换为维度*Cout 的*输出特征。线性层学习一个大小的矩阵C我ñ× (CØ ü Ť/ 2)，逐点连接产生维度*C out*的输出。

由于输出特征结合了逐点特征和局部聚合特征，堆叠 VFE 层对体素内的点交互进行编码，并使最终特征表示能够学习描述性形状信息。voxel-wise 特征是通过对 VFE 的输出进行变换来获得的− n 进入 电阻C 通过 FCN 并应用 element-wise Maxpool 其中 C是体素特征的维度，如图2所示。